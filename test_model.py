# -*- coding: utf-8 -*-
"""test_model.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/15F6sCtTOAEc1z-PWzdxrpYZG7jXptTaP
"""

import numpy as np
import time
import torch
import torch.nn as nn
import torch.nn.functional as F
import torch.optim as optim
import torchvision
from torch.utils.data.sampler import SubsetRandomSampler
import torchvision.transforms as transforms

import matplotlib.pyplot as plt

# Importing VGG - our base model - with pretrained weights
import torchvision.models

!nvidia-smi

from google.colab import drive
drive.mount('/content/drive')

device = torch.device
device = torch.device("cuda" if torch.cuda.is_available() else "cpu")
print(device, "is in use")

"""## Model"""

# Constructing Neural Network
class GeoGuesser(nn.Module):
    def __init__(self, encoder_mode = False, encode_to_fc_mode = False):
        super(GeoGuesser, self).__init__()

        self.name = "GeoGuesser"
        self.encoder_mode = encoder_mode
        self.encode_to_fc_mode = encode_to_fc_mode


        # Recall that nn.Conv2D(in_channel, out_channel, kernel_size, stride, padding) is what's required
        # WE STILL NEED TO SET THE DIMENSIONS APPROPRIATELY
        self.convol_model = nn.Sequential(
            nn.Conv2D(3, 5, 4, padding = 1, stride = 2),
            # w = h = (250-4-2(1))/2 + 1 = 123 => 123*123*5
            nn.Conv2d(5, 10, 3, padding = 1, stride = 2),
            # (123-3-2(1))/2 + 1 = 60 => 60*60*10
            nn.Conv2d(10, 15, 4, padding = 1, stride = 2),
            # (60-4-2(1))/2 + 1 = 28 => 28*28*15
            nn.conv2d(15, 15, 3, padding = 1)
            # (28-3-2(1)) + 1 = 24 => 24*24*15
        )

        # Aim for features less than 100
        # 5 Layers likely going to lead to overfit - fix this
        # Also try to go for 3-layers-ish
        self.fc_model = nn.Sequential(
            nn.Linear(24*24*15, 2000),
            nn.ReLU(),
            nn.Linear(2000, 500),
            nn.ReLU(),
            nn.Linear(500, 150),
            nn.ReLU(),
            nn.Linear(150, 80)
        )

        # Also consider:
        # self.encoder = nn.Sequential(
        #     nn.Conv2D(3, 20, 5, stride = 3, padding = 2),
        #     # w = h = (250-5+2+2)/3 + 1 = 84 => 84*84*20
        #     nn.ReLU(),
        #     nn.Conv2D(20, 50, 5, stride = 3, padding = 1),
        #     # w = h = (84-5+1+1)/3 + 1 = 28 => 28*28*50
        #     nn.ReLU(),
        #     nn.Conv2D(50, 100, 10)
        #     # w = h = (28 - 10) + 1 = 19 => 19*19*100
        # )
        # # In this case, we'd aim for a specific embedding space dimension
        # self.decoder = nn.Sequential(
        #     nn.ConvTranspose2d(100, 50, 10),
        #     nn.ReLU(),
        #     nn.ConvTranspose2d(50, 20, 5, stride = 2, padding = 1, output_padding = 1),
        #     nn.ReLU(),
        #     nn.ConvTranspose2d(20, 3, 5, stride = 2, padding = 1, output_padding = 1),
        #     nn.Sigmoid()
        # )
        # self.embd_spc_nn = nn.Sequential(
        #     # Start with the dimension of the embedded space
        #     nn.Linear(19*19*100, 10000),
        #     nn.ReLU(),
        #     nn.Linear(10000, 5000),
        #     nn.ReLU(),
        #     nn.Linear(5000, 2000),
        #     nn.ReLU(),
        #     nn.Linear(2000, 500)
        # )
    
    def forward(self, x):
        if(self.encoder_mode):
            x = self.encoder(x)
            x = self.decoder(x)
            print("Encoder mode selected")

        elif(self.encode_to_fc_mode):
            x = self.encoder(x)
            x = self.embd_spc_nn(x)
            print("Encoder to full-connected mode selected")
        
        else:
            x = self.convol_model(x)
            x = self.fc_model(x)
            print("No encoder selected")
            
        return x

# Constants to use when calling the TRAIN function
train_cnn = 0
train_encoder = 1
train_fc = 2


# Training Code
# other_param is just a placeholder
def train_conv(model, train_data, criterion, optimizer, batch_size=64):
    """
    Train model, return error and loss for SINGLE EPOCH
    Assume that the train_conv is going to train a normal convolution -> fc layer

    Args:
    model: CNN model that we are training
    train_data: training dataset (must be a DataLoader)
    criterion: loss criterion, defined in train function
    optimizer: optimizer, defined in train function

    Ideally the dataset for this NN should be an ImageFolder?
    """
    # To update and return
    epoch_error = 0
    epoch_loss = 0
    for i, data in enumerate(train_data):
        # Train model
    
        #############################################
        #To Enable GPU Usage
        if use_cuda and torch.cuda.is_available():
            device = torch.device("cuda")
            model.cuda()
        else:
            device = torch.device("cpu")

        imgs = imgs.to(device)
        labels = labels.to(device)
        #############################################

        out = model.encoder(i)               # perform fwd pass
        loss = criterion(out, data)          # compute total loss
        loss.backward()                      # backward pass
        optimizer.step()                     # make updates for each parameter
        optimizer.zero_grad()                # clean up step

    epoch_loss = float(loss)/batch_size                  # compute average loss across entire batch_size
    epoch_error = 1 - get_accuracy(model, train_data)    # compute error

    return epoch_error, epoch_loss

def train_autoencoder(model, train_data):
    """
    Train model, return error and loss for SINGLE EPOCH
    Assume that the train_autoencoder is going to train an autoencoder
    """
    epoch_error = 0
    epoch_loss = 0

    # Need to unfreeze all parameters in the encoder layer:
    # This is so that the code doesn't break if we train the FC layer
    for param in model.encoder.parameters():
        param.requires_grad = True

    for i, data in enumerate(train_data):
        # Train model
        # Remember to use input both as input and target!!

        #############################################
        #To Enable GPU Usage
        if use_cuda and torch.cuda.is_available():
            device = torch.device("cuda")
            model.cuda()
        else:
            device = torch.device("cpu")

        imgs = imgs.to(device)
        labels = labels.to(device)
        #############################################

        reconstruction = model(i)
        loss = criterion(reconstruction, i)
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()

        epoch_loss = float(loss)

    return epoch_error, epoch_loss

def train_encode_fc(model, train_data):
    """
    Train model, return error and loss for SINGLE EPOCH
    Assume that the ENCODER has already been trained; train the FC layer of the model ONLY
    """
    epoch_error = 0
    epoch_loss = 0

    # Need to freeze all parameters in the encoder layer:
    for param in model.encoder.parameters():
        param.requires_grad = False

    for i, data in enumerate(train_data):
        # Train model
        # Reminder to NOT TRAIN ENCODER LAYER
    
        #############################################
        #To Enable GPU Usage
        if use_cuda and torch.cuda.is_available():
            device = torch.device("cuda")
            model.cuda()
        else:
            device = torch.device("cpu")

        imgs = imgs.to(device)
        labels = labels.to(device)
        #############################################

        out = model(i)
        loss = criterion(out, data)
        loss.backward()
        optimizer.step()
        optimizer.zero_grad()

        # need to put code in that compute sloss
    return epoch_error, epoch_loss

def valid_err_and_loss(model, valid_data, is_encoder):
    """
    Helper function for train; this is used to mark the error and loss on the validation model 
    """
    error = 0
    loss = 0
    criterion = nn.MSELoss()

    #############################################
    #To Enable GPU Usage
    if use_cuda and torch.cuda.is_available():
        device = torch.device("cuda")
        model.cuda()
    else:
        device = torch.device("cpu")

    imgs = imgs.to(device)
    labels = labels.to(device)
    #############################################

    num_iters = 0           # used to keep track of the # of iterations (used to calculate average loss)

    if is_encoder:
        # Validate like encoder; MEANING INPUT AND TARGET IS THE SAME
        total_losses = 0    # used to calculate the average loss over the entire validation set

        for i, data in enumerate(valid_data):
            # Go over all the dataset and get error and loss

            reconstruction = model(i)
            iterLoss = criterion(reconstruction, data)
            iterLoss.backward()
            optimizer.step()
            optimizer.zero_grad()

            total_losses += iterLoss
            num_iters += 1

    else:
        # Validate network like it is a CNN
        total_losses = 0

        for i, data in enumerate(valid_data):
            # Go over all the dataset and get error and loss

            out = model(i)
            iterLoss = criterion(out, data)
            iterLoss.backward()
            optimizer.step()
            optimizer.zero_grad()

            total_losses += iterLoss
            num_iters += 1

        # getting the average loss over the validation set
        loss = total_losses / num_iters
    
    return error, loss

def train(model, train_data, valid_data, seed, train_mode, batch_size, other_param):
    """
    Use seed to create controlled results for comparison
    Make sure to load train_data in terms of DataLoader

    Make sure train_mode is an integer from 0 to 2, where 
    - 0 represents normal convolution/fc training
    - 1 represents autoencoder training
    - 2 represents fc training (after autoencoder)
    """

    # Use Mean Squared Error for our loss since this is a regression problem
    # Optimizer, I just used what we've been using for the entire course
    criterion = nn.MSELoss()
    optimizer = optim.SGD(net.parameters(), lr=learning_rate, momentum=0.9)

    # Set up zeroes for statistics for analysis
    train_err = np.zeros(num_epochs)
    train_loss = np.zeros(num_epochs)
    val_err = np.zeros(num_epochs)
    val_loss = np.zeros(num_epochs)

    for i in epochs_num:
        
        if (train_mode == 0):
            t_err, t_loss = train_conv(model, train_data, criterion, optimizer, batch_size)

        elif (train_mode == 1):
            t_err, t_loss = train_autoencoder()

        elif (train_mode == 2):
            t_err, t_loss = train_encode_fc()

        else:
            print("Train_mode_not_valid")
        
        # This part is kinda sketchy, but if train_mode == 1, it should be autoencoder, otherwise it should just be aiming for target
        v_err, v_loss = valid_err_and_loss(model, valid_data, (train_mode == 1))

        train_err[i], train_loss[i], val_err[i], val_loss[i] = t_err, t_loss, v_err, v_loss
    
    return train_err, train_loss, val_err, val_loss

"""## Dataset Processing"""

from torchvision import transforms
image_transforms = {
    transforms.Compose([
        transforms.RandomRotation(degrees=15),
        transforms.RandomHorizontalFlip()
    ])
}

"""
Processing our dataset and creating training, validation, and testing sets
"""

# Defining a set of transforms to pre-process our images
transform = transforms.Compose([transforms.ToTensor(), transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))])

# This is an ImageFolder in case we want to classify our photos
dataset = torchvision.datasets.ImageFolder('/content/drive/MyDrive/APS360/New_Image', transform)
numClasses = len(dataset.classes)                                                             # Will be used to define the number of output neurons in the final classification layer

#######################################################################################################
# Converting the dataset to train, validation and test loaders
relevant_indices = []
    
# Filling out the relevant_indices list with the indices of all images in the dataset. 
for i in range(len(dataset)):
  relevant_indices.append(i)
    
# Want 70-15-15 split
np.random.seed(1000) # Fixed numpy random seed for reproducible shuffling
np.random.shuffle(relevant_indices)

# Dividing up the indices into training, validation and testing sets:
trainSplit = int(len(relevant_indices) * 0.7) # split at 70% for training
valSplit = trainSplit + int(len(relevant_indices) * 0.15) # split at 15% for validation

# split into training,validation, and testing indices
relevant_train_indices, relevant_val_indices, relevant_test_indices = relevant_indices[:trainSplit], relevant_indices[trainSplit:valSplit], relevant_indices[valSplit:]
print("Size of training set:", len(relevant_train_indices), "\nSize of val set:", len(relevant_val_indices), "\nSize of testing set:", len(relevant_test_indices))

train_sampler = SubsetRandomSampler(relevant_train_indices)
train_loader = torch.utils.data.DataLoader(dataset, batch_size=64,
                                               num_workers=1, sampler=train_sampler)
    
val_sampler = SubsetRandomSampler(relevant_val_indices)
val_loader = torch.utils.data.DataLoader(dataset, batch_size=64,
                                              num_workers=1, sampler=val_sampler)
    
test_sampler = SubsetRandomSampler(relevant_test_indices)
test_loader = torch.utils.data.DataLoader(dataset, batch_size=64,
                                              num_workers=1, sampler=test_sampler)

device

"""## Training Code"""

"""
get_accuracy taken from Tutorial 3a

Args:
    - model: the neural network model that we are training
    - train: a boolean value that indicates whether we're using our training set or our validation set
"""
def get_accuracy(model, train=False):
    if train:
        data = train_loader
    else:
        data = val_loader

    correct = 0
    total = 0
    for imgs, labels in iter(data):
        
        #############################################
        #To Enable GPU Usage
        if torch.cuda.is_available():
          device = torch.device("cuda")
          model.cuda()
        else:
          device = torch.device("cpu")

        imgs = imgs.to(device)
        labels = labels.to(device)
        #############################################

        output = model(imgs)
        
        #select index with maximum prediction score
        pred = output.max(1, keepdim=True)[1]
        correct += pred.eq(labels.view_as(pred)).sum().item()
        total += imgs.shape[0]
        
    return correct / total

"""
Training function - taken from Tutorial 3a
Args:
    - model: the model we are currently training
    - data: a DataLoader object. Should ideally be our training dataset
    - batch_size: Default arg = 64
    - num_epochs: number of epochs. Default argument = 1
"""
def trainBaseline(model, data, batch_size=64, num_epochs=1):
    criterion = nn.CrossEntropyLoss()
    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)

    iters, losses, train_acc, val_acc = [], [], [], []

    # training
    n = 0 # the number of iterations
    for epoch in range(num_epochs):
        for imgs, labels in iter(data):
              
            #############################################
            #To Enable GPU Usage
            if torch.cuda.is_available():
              device = torch.device("cuda")
              model.cuda()
            else:
              device = torch.device("cpu")

            imgs = imgs.to(device)
            labels = labels.to(device)
            #############################################

            out = model(imgs)             # forward pass
            loss = criterion(out, labels) # compute the total loss
            loss.backward()               # backward pass (compute parameter updates)
            optimizer.step()              # make the updates for each parameter
            optimizer.zero_grad()         # a clean up step for PyTorch

            # save the current training information
            iters.append(n)
            losses.append(float(loss)/batch_size)             # compute *average* loss
            train_acc.append(get_accuracy(model, train=True)) # compute training accuracy 
            val_acc.append(get_accuracy(model, train=False))  # compute validation accuracy
            
            n += 1

        print("Epoch %d: Loss %f, Train Acc %f, Val Acc %f" % (epoch+1, loss, train_acc[-1], val_acc[-1]))

        # Save the model information and write it to disk every 5 epochs:
        """
        NOTE: If you want to load model weights use the following code:
        torch.load('PATH_TO_WEIGHTS')
        Path files typically look like 'cnn_epochX.pth' where X is your epoch number (some multiple of 10)
        """
        if epoch % 5 == 0:
            model_path = "cnn_epoch{0}.pth".format(epoch)
            torch.save(model.state_dict(), model_path)

    # plotting
    plt.title("Training Curve")
    plt.plot(iters, losses, label="Train")
    plt.xlabel("Iterations")
    plt.ylabel("Loss")
    plt.show()

    plt.title("Training Curve")
    plt.plot(iters, train_acc, label="Train")
    plt.plot(iters, val_acc, label="Validation")
    plt.xlabel("Iterations")
    plt.ylabel("Training Accuracy")
    plt.legend(loc='best')
    plt.show()

    print("Final Training Accuracy: {}".format(train_acc[-1]))
    print("Final Validation Accuracy: {}".format(val_acc[-1]))

"""## VGG16 Implementation"""

train_iter = iter(train_loader)
features, labels = next(train_iter)

features_shape, labels_shape = features.shape, labels.shape

#number of countries in Europe
n_classes = 19

vgg16 = torchvision.models.vgg16(pretrained=True)

# freeze model weight
for param in vgg16.features.parameters():
    param.requires_grad = False

for param in vgg16.classifier.parameters():
    param.requires_grad = True

# Redeclare classifier layer
vgg16.classifier = nn.Sequential(
    nn.Linear(25088, 2000),
    nn.ReLU(),
    nn.Dropout(0.25),
    nn.Linear(2000, 500), 
    nn.ReLU(),
    nn.Dropout(0.25),
    nn.Linear(500, 50),
    nn.ReLU(),
    nn.Dropout(0.25),
    nn.Linear(50, n_classes),
    nn.LogSoftmax(dim=1)
)

#** Uncomment this when training to increase performance **#
# Commented out since there is no GPU present in deepnotes
#Move to gpu
vgg16 = vgg16.to('cuda')
#Distribute across 2 gpus
vgg16 = nn.DataParallel(vgg16)

# Testing
trainBaseline(vgg16, train_loader)

"""<a style='text-decoration:none;line-height:16px;display:flex;color:#5B5B62;padding:10px;justify-content:end;' href='https://deepnote.com?utm_source=created-in-deepnote-cell&projectId=d3e35070-2923-4ca1-b806-34dded52300c' target="_blank">
<img alt='Created in deepnote.com' style='display:inline;max-height:16px;margin:0px;margin-right:7.5px;' src='data:image/svg+xml;base64,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' > </img>
Created in <span style='font-weight:600;margin-left:4px;'>Deepnote</span></a>
"""